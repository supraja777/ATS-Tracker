{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4Z8tY+KCK+/P76S3fY5WU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supraja777/ATS-Tracker/blob/main/Small_Language_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets\n",
        "!pip install tiktoken\n",
        "!pip install numpy matplotlib tqdm\n",
        "!pip install accelerate wandb tensorboard"
      ],
      "metadata": {
        "id": "UgIw0PnzNnDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "df = load_dataset(\"roneneldan/TinyStories\")\n",
        "#print(df)"
      ],
      "metadata": {
        "id": "_L3o8Wq4IJp5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization with BPE\n",
        "\n",
        "import tiktoken\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "encoding = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "def processing(sample_text):\n",
        "  ids = encoding.encode_ordinary(sample_text['text'])\n",
        "  out = {'ids': ids, 'len': len(ids)}\n",
        "  return out\n",
        "\n"
      ],
      "metadata": {
        "id": "UPU08vHBIUDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Model Architecture\n",
        "\n",
        "from dataclasses import dataclass\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "@dataclass\n",
        "class GPTConfig:\n",
        "  block_size: int = 128\n",
        "  vocab_size: int = 50257\n",
        "  n_layer: int = 6\n",
        "  n_head: int = 6\n",
        "  n_embd: int = 384\n",
        "  dropout: float = 0.1\n",
        "  bias: bool = True"
      ],
      "metadata": {
        "id": "LZZuVdvUJGmz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing Layer Normalization\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, ndim, bias):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.ones(ndim))\n",
        "    self.bias = nn.Parameter(torch.zeros(ndim)) # is bias else None\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.layer_norm(x, self.weight.shape, self.weight, self.bias, 1e-5)\n",
        ""
      ],
      "metadata": {
        "id": "hO0azpZnO286"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config,\n",
        "    self.transformer = nn.ModuleDict(dict(\n",
        "        wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "        wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "        drop = nn.Dropout(config.dropout),\n",
        "        h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]), # Initializing transformer block\n",
        "        ln_f = LayerNorm(config.n_embd, config.bias)\n",
        "    ))"
      ],
      "metadata": {
        "id": "JzU8gzl4JGhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "maUczOF-JGad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJPFXML4JGRd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}